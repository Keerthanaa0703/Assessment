# -*- coding: utf-8 -*-
"""LVADSUSR93_Keerthanaa_Lab_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PO-Kk7Fvu0dMWcyQNcMMNFkinM9xEmue
"""

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt


# Load your dataset
df_seeds = pd.read_csv('/content/seeds.csv')

# Preprocess the data (handle missing values, etc.)
print("Missing values before handling:")
print(df_seeds.isnull().sum())

#Filling missing values
df_seeds['Area'] = df_seeds['Area'].fillna(df_seeds['Area'].mean()).astype(float)
df_seeds['Perimeter'] = df_seeds['Perimeter'].fillna(df_seeds['Perimeter'].mean()).astype(float)
df_seeds['Compactness'] = df_seeds['Compactness'].fillna(df_seeds['Compactness'].mean()).astype(float)
df_seeds['Length of kernel'] = df_seeds['Length of kernel'].fillna(df_seeds['Length of kernel'].mean()).astype(float)
df_seeds['Width of kernel'] = df_seeds['Width of kernel'].fillna(df_seeds['Width of kernel'].mean()).astype(float)
df_seeds['Asymmetry coefficient'] = df_seeds['Asymmetry coefficient'].fillna(df_seeds['Asymmetry coefficient'].mean()).astype(float)
df_seeds['Length of kernel groove'] = df_seeds['Length of kernel groove'].fillna(df_seeds['Length of kernel groove'].mean()).astype(float)
print(df_seeds)

# Selecting features for clustering
features_seeds = df_seeds[['Area', 'Perimeter', 'Compactness', 'Length of kernel', 'Width of kernel', 'Asymmetry coefficient', 'Length of kernel groove']]

# Scaling the features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
features = ['Area', 'Perimeter', 'Compactness', 'Length of kernel', 'Width of kernel', 'Asymmetry coefficient', 'Length of kernel groove']
X = df_seeds[features]
features_scaled = scaler.fit_transform(X)




# from sklearn.preprocessing import StandardScaler

# # Select the features to scale
# features = ['Area', 'Perimeter', 'Compactness', 'Length of kernel', 'Width of kernel', 'Asymmetry coefficient', 'Length of kernel groove']

# # Extract the selected features from your DataFrame
# X = df[features]

# # Initialize the StandardScaler
# scaler = StandardScaler()

# # Fit and transform the selected features
# X_scaled = scaler.fit_transform(X)


# Use the Elbow method to find the optimal number of clusters
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(features_scaled)
    wcss.append(kmeans.inertia_)

# Plot the results of the Elbow method
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS') # Within cluster sum of squares
plt.show()

# Choose the number of clusters (k) and fit the K-Means model
k = 3 # Example number of clusters
kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)
clusters = kmeans.fit_predict(features_scaled)

# Add the cluster data to the original dataframe
df_seeds['cluster'] = clusters

# Visualize the clusters (optional, for 2D visualization)
plt.scatter(df_seeds['Area'], df_seeds['Perimeter'], c=df_seeds['cluster'], cmap='viridis')
plt.title('Clusters of Seeds')
plt.xlabel('Area')
plt.ylabel('Perimeter')
plt.show()

# Save the clustered data to a new CSV file
df_seeds.to_csv('seeds_with_clusters.csv', index=False)